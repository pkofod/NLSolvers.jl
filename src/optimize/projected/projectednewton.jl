"""
# ProjectedNewton
## Constructor
```julia
    ProjectedNewton(; epsilon=1e-8)
```

`epsilon` determines the threshold for whether a bound is approximately active or not, see eqn. (32) in [1].

## Description
ProjectedNewton second order for bound constrained optimization. It's an active set and allows for rapid exploration of the constraint face. It employs a modified Armijo-line search that takes the active set into account. Details can be found in [1].

## References
[1] http://www.mit.edu/~dimitrib/ProjectedNewton.pdf
"""
struct ProjectedNewton{T}
    œµ::T
end
ProjectedNewton(; epsilon=1e-12) = ProjectedNewton(epsilon)

modelscheme(::ProjectedNewton) = Newton()
"""
    diagrestrict(x, c, i)

Returns the correct element of the Hessian according to the active set and the diagonal matrix described in [1].

[1] http://www.mit.edu/~dimitrib/ProjectedNewton.pdf
"""
function diagrestrict(x::T, c, i) where T
    if !c
        # If not binding, then return the value
        return x
    else
        # If binding, then return 1 if the diagonal or 0 otherwise
        T(i)
    end
end

function is_œµ_active(x, lower, upper, ‚àáfx, œµ‚àáf=eltype(x)(0))
    # it is requied that œµ ‚©Ω min(U_i - L_i)/2 to uniquely choose
    # an underestimate of the inactive set or else there would be
    # two ways of defining ùìê^œµ.
    lowerbinding = x <= lower + œµ‚àáf
    upperbinding = x >= upper - œµ‚àáf

    pointing_down = ‚àáfx >= 0
    pointing_up   = ‚àáfx <= 0

    lower_active = lowerbinding && pointing_down
    upper_active = upperbinding && pointing_up

    lower_active || upper_active
end

function solve(prob::MinProblem, x0, scheme::ProjectedNewton, options::MinOptions)
    t0 = time()

    x0, B0 = x0, [1.0 0.0; 0.0 1.0]
    lower, upper = bounds(prob)
    œµ‚àáf = scheme.œµ

    !any(clamp.(x0, lower, upper) .!= x0) || error("Initial guess not in the feasible region")

    linesearch = ArmijoBertsekas()
    mstyle = OutOfPlace()

    objvars = prepare_variables(prob, scheme, x0, copy(x0), B0)
    f0, ‚àáf0 = objvars.fz, norm(objvars.‚àáfz, Inf) # use user norm
    fz, ‚àáfz = objvars.fz, objvars.‚àáfz # use user norm
    fx, ‚àáfx = fz, copy(‚àáfz)
    B = B0
    x = copy(x0)
    z = copy(x0)
    Tf = typeof(fz)
    is_first=false
    Ix = Diagonal(z.*0 .+ 1)
    for i = 1:options.maxiter
        x = copy(z)
        fx = copy(fz)
        ‚àáfx = copy(‚àáfz)

        activeset = is_œµ_active.(x, lower, upper, ‚àáfx, œµ‚àáf)
        incactiveset = .!(activeset)

        # The hessian needs to be adapted to ignore the active region
        binding = .!(incactiveset*incactiveset')
        Hhat = diagrestrict.(inv(B), binding, Ix)

        # Update current gradient and calculate the search direction
        d = clamp.(x.-Hhat*‚àáfx, lower, upper).-x # solve Bd = -‚àáfx
        œÜ = _lineobjective(mstyle, prob, prob.objective, ‚àáfz, z, x, d, fz, dot(‚àáfz, d))

        # Perform line search along d
        # Also returns final step vector and update the state
        Œ±, f_Œ±, ls_success = find_steplength(mstyle, linesearch, œÜ, Tf(1), ‚àáfz, activeset, lower, upper, x, d, ‚àáfx, activeset)
        # # Calculate final step vector and update the state
        s = @. Œ± * d
        z = @. x + s
        s = clamp.(z, lower, upper) - x
        z = x + s
        
        # Update approximation
        fz, ‚àáfz, B, s, y = update_obj(prob.objective, s, ‚àáfx, z, ‚àáfz, B, Newton(), is_first)
        if norm(x.-clamp.(x.-‚àáfx, lower, upper), Inf) < 1e-6
            return z, fz, i
        end
    end
    @show z.-min.(upper, max.(z.-‚àáfz, lower))
  z, fz, options.maxiter
end

"""
# ArmijoBertsekas
## Constructor
```julia
    ArmijoBertsekas()
```
## Description
ArmijoBertsekas is the modified Armijo backtracking line search described in [1]. It takes into account whether an element of the gradient is active or not.

## References
[1] http://www.mit.edu/~dimitrib/ProjectedNewton.pdf
"""
struct ArmijoBertsekas{T1, T2, T3, TR} <: LineSearcher
    ratio::T1
    decrease::T1
    maxiter::T2
    interp::T3
    steprange::TR
    verbose::Bool
end
ArmijoBertsekas(; ratio=0.5, decrease=1e-4, maxiter=50,
               steprange=(0.0, Inf), interp=FixedInterp(),
               verbose=false) =
 ArmijoBertsekas(ratio, decrease, maxiter, interp, steprange, verbose)

function find_steplength(mstyle, ls::ArmijoBertsekas, œÜ::T, Œª, ‚àáfx, Ibool, lower, upper, x, p, g, activeset) where T
    #== unpack ==#
    œÜ0, dœÜ0 = œÜ.œÜ0, œÜ.dœÜ0
    Tf = typeof(œÜ0)
    ratio, decrease, maxiter, verbose = Tf(ls.ratio), Tf(ls.decrease), ls.maxiter, ls.verbose

    #== factor in Armijo condition ==#
    t0 = decrease*dœÜ0 # dphi0 should take into account the active set
    iter, Œ±, Œ≤ = 0, Œª, Œª # iteration variables
    f_Œ± = œÜ(Œ±)   # initial function value
    x‚Å∫ = retract.(lower, upper, x, p, Œ±)

    if verbose
        println("Entering line search with step size: ", Œª)
        println("Initial value: ", œÜ0)
        println("Value at first step: ", f_Œ±)
    end
    is_solved = isfinite(f_Œ±) && f_Œ± <= œÜ0 - decrease*sum(bertsekas_R.(x, x‚Å∫, g, p, Œ±, activeset))
    while !is_solved && iter <= maxiter
        iter += 1
        Œ≤, Œ±, f_Œ± = interpolate(ls.interp, œÜ, œÜ0, dœÜ0, Œ±, f_Œ±, ratio)
        x‚Å∫ = retract.(lower, upper, x, p, Œ±)
        is_solved = isfinite(f_Œ±) && f_Œ± <= œÜ0 - decrease*sum(bertsekas_R.(x, x‚Å∫, g, p, Œ±, activeset))
    end

    ls_success = iter >= maxiter ? false : true

    if verbose
        !ls_success && println("maxiter exceeded in backtracking")
        println("Exiting line search with step size: ", Œ±)
        println("Exiting line search with value: ", f_Œ±)
    end
    return Œ±, f_Œ±, ls_success
end

bertsekas_R(x, x‚Å∫, g, p, Œ±, i) = i ? g*(x-x‚Å∫) : Œ±*p*g
# defined univariately
retract(lower, upper, x, p, Œ±) = min(upper, max(lower, x-Œ±*p))